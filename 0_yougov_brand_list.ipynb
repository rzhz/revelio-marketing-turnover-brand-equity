{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c718fdb-32c1-45df-a375-9e34a4108dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory containing the files\n",
    "directory = '/work/SafeGraph/revelio/code'\n",
    "fvdirectory = '/work/SafeGraph/revelio/data/yougov'\n",
    "\n",
    "# Load the YouGov file\n",
    "df = pd.read_stata(os.path.join(fvdirectory, \"ugov_cik.dta\"))\n",
    "\n",
    "# Define a function to check if CIK is valid\n",
    "def is_valid_cik(cik):\n",
    "    return pd.notna(cik)\n",
    "\n",
    "# Filter the DataFrame to include only rows with valid CIKs, 'conm' stands for company name\n",
    "valid_ciks = df[df['cik'].apply(is_valid_cik)][['cik', 'conm']]\n",
    "\n",
    "# Sort by 'cik' and 'conm', putting non-empty 'conm' values first\n",
    "# NaNs are sorted to the end by default\n",
    "valid_ciks = valid_ciks.sort_values(by=['cik', 'conm'], ascending=[True, False])\n",
    "\n",
    "# Drop duplicates, keeping the first (which is now the first non-empty 'conm' for each 'cik')\n",
    "valid_ciks = valid_ciks.drop_duplicates(subset='cik', keep='first')\n",
    "\n",
    "# Creating the second list (invalid CIKs)\n",
    "invalid_ciks = df[~df['cik'].apply(is_valid_cik)]['Brand'].drop_duplicates()\n",
    "\n",
    "valid_ciks.to_csv(os.path.join(directory, 'public_brand_list.csv'), index=False)\n",
    "invalid_ciks.to_csv(os.path.join(directory, 'private_brand_list.csv'), index=False)\n",
    "#The remaining code is for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a7c85a-dbf3-40df-b66a-715a3af43753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ugov_id      Brand       Date    year  month  week     cik  \\\n",
      "0        22013.0     Ensure 2007-06-03  2007.0    6.0  22.0  1800.0   \n",
      "1        22017.0   Glucerna 2007-06-03  2007.0    6.0  22.0  1800.0   \n",
      "2        22019.0  Pedialyte 2007-06-03  2007.0    6.0  22.0  1800.0   \n",
      "3        22020.0  PediaSure 2007-06-03  2007.0    6.0  22.0  1800.0   \n",
      "4        22013.0     Ensure 2007-06-06  2007.0    6.0  23.0  1800.0   \n",
      "...          ...        ...        ...     ...    ...   ...     ...   \n",
      "18456    22019.0                   NaT  2020.0    8.0   NaN  1800.0   \n",
      "18457    22013.0                   NaT  2020.0    8.0   NaN  1800.0   \n",
      "18458    22017.0                   NaT  2020.0    8.0   NaN  1800.0   \n",
      "18459    22020.0                   NaT  2020.0    8.0   NaN  1800.0   \n",
      "6099983      NaN                   NaT  2020.0    8.0  35.0  1800.0   \n",
      "\n",
      "                        conm   gvkey  tik  ... Score_currentcustomer  \\\n",
      "0        ABBOTT LABORATORIES  1078.0  ABT  ...                   NaN   \n",
      "1        ABBOTT LABORATORIES  1078.0  ABT  ...                   NaN   \n",
      "2        ABBOTT LABORATORIES  1078.0  ABT  ...                   NaN   \n",
      "3        ABBOTT LABORATORIES  1078.0  ABT  ...                   NaN   \n",
      "4        ABBOTT LABORATORIES  1078.0  ABT  ...                   NaN   \n",
      "...                      ...     ...  ...  ...                   ...   \n",
      "18456    ABBOTT LABORATORIES  1078.0  ABT  ...                   NaN   \n",
      "18457    ABBOTT LABORATORIES  1078.0  ABT  ...                   NaN   \n",
      "18458    ABBOTT LABORATORIES  1078.0  ABT  ...                   NaN   \n",
      "18459    ABBOTT LABORATORIES  1078.0  ABT  ...                   NaN   \n",
      "6099983                          NaN       ...                   NaN   \n",
      "\n",
      "        Score_formercustomer Score_impr Score_purchase  Score_quality  \\\n",
      "0                        NaN  28.769979            NaN      22.376650   \n",
      "1                        NaN  10.111188            NaN       3.127172   \n",
      "2                        NaN  32.870049            NaN      10.284920   \n",
      "3                        NaN  15.948575            NaN      16.539263   \n",
      "4                        NaN  30.565840            NaN      20.501186   \n",
      "...                      ...        ...            ...            ...   \n",
      "18456                    NaN        NaN            NaN            NaN   \n",
      "18457                    NaN        NaN            NaN            NaN   \n",
      "18458                    NaN        NaN            NaN            NaN   \n",
      "18459                    NaN        NaN            NaN            NaN   \n",
      "6099983                  NaN        NaN            NaN            NaN   \n",
      "\n",
      "         Score_rec  Score_reput  Score_sat  Score_value  Score_wom  \n",
      "0         0.000000    18.241835   4.065323    18.658791        NaN  \n",
      "1         6.219597     9.728978   4.864489    -1.355108        NaN  \n",
      "2        11.674774    29.325920   6.219597     1.007644        NaN  \n",
      "3         5.420431    13.794302   7.574705    -7.366227        NaN  \n",
      "4        23.533768    16.583258   1.298614    14.143869        NaN  \n",
      "...            ...          ...        ...          ...        ...  \n",
      "18456          NaN          NaN        NaN          NaN        NaN  \n",
      "18457          NaN          NaN        NaN          NaN        NaN  \n",
      "18458          NaN          NaN        NaN          NaN        NaN  \n",
      "18459          NaN          NaN        NaN          NaN        NaN  \n",
      "6099983        NaN          NaN        NaN          NaN        NaN  \n",
      "\n",
      "[18461 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[df['cik']==1800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fefad968-ca8f-4863-a57b-58caa93c99fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for fuzzy matching the first observation: 709.3056681156158 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Function for fuzzy matching\n",
    "def fuzzy_match(brand, company_list, scorer, cutoff):\n",
    "    match = process.extractOne(brand, company_list, scorer=scorer, score_cutoff=cutoff)\n",
    "    return match[0] if match else None\n",
    "\n",
    "# Paths\n",
    "directory = '/work/SafeGraph/revelio/code'\n",
    "sdirectory = '/work/SafeGraph/revelio/data'\n",
    "\n",
    "# Read the private list\n",
    "private_list = pd.read_csv(os.path.join(directory, \"private_brand_list.csv\"))\n",
    "private_list['Brand'] = private_list['Brand'].str.lower().str.replace(' ', '')\n",
    "\n",
    "# List to hold dataframes\n",
    "dfs = []\n",
    "\n",
    "# Read and process dataframes\n",
    "for i in range(32):\n",
    "    file_path = os.path.join(sdirectory, f\"company_ref_00{str(i).zfill(2)}_part_00.parquet\")\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['company_nospace'] = df['company'].str.lower().str.replace(' ', '')\n",
    "    df['primary_name_nospace'] = df['primary_name'].str.lower().str.replace(' ', '')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "cik_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Direct Matching\n",
    "direct_matches = cik_df[cik_df['company_nospace'].isin(private_list['Brand']) | \n",
    "                        cik_df['primary_name_nospace'].isin(private_list['Brand'])]\n",
    "\n",
    "# Add a 'Brand' column to direct_matches\n",
    "direct_matches = direct_matches.assign(\n",
    "    Brand=lambda x: x['company_nospace'].where(x['company_nospace'].isin(private_list['Brand']),\n",
    "                                              x['primary_name_nospace'])\n",
    ")\n",
    "\n",
    "\n",
    "# Identifying unmatched entries in private_list\n",
    "unmatched_brands = private_list[~private_list['Brand'].isin(direct_matches['company_nospace']) &\n",
    "                                ~private_list['Brand'].isin(direct_matches['primary_name_nospace'])]\n",
    "\n",
    "# Identifying unmatched entries in cik_df\n",
    "unmatched_cik_df = cik_df[~cik_df['company_nospace'].isin(direct_matches['company_nospace']) &\n",
    "                          ~cik_df['primary_name_nospace'].isin(direct_matches['primary_name_nospace'])]\n",
    "\n",
    "# Preparing company list for fuzzy matching\n",
    "company_list = unmatched_cik_df['company_nospace'].tolist()\n",
    "\n",
    "# Perform fuzzy matching for the first observation and measure the time\n",
    "start_time = time.time()\n",
    "first_brand = unmatched_brands['Brand'].iloc[0]\n",
    "first_brand_fuzzy_match = fuzzy_match(first_brand, company_list, scorer=fuzz.WRatio, cutoff=80)\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the time taken\n",
    "print(f\"Time taken for fuzzy matching the first observation: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8cdd20d-48a9-4c0e-8f8a-4084e737d131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(544, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched_brands.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
